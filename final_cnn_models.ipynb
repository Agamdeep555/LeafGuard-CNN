{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12365137,"sourceType":"datasetVersion","datasetId":7796214}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, cv2, numpy as np\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetV2B3\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\n# âœ… STEP 1: Paths - Updated for Corn crop only\nBASE = \"/kaggle/input/team-11a-crop-wise-dataset/Dataset_annam\"\nRAW_TRAIN = os.path.join(\"/kaggle/input/team-11a-crop-wise-dataset/Dataset_annam/Corn/Train\")  # Only Corn training data\nRAW_VAL = os.path.join(\"/kaggle/input/team-11a-crop-wise-dataset/Dataset_annam/Corn/Valid\")    # Only Corn validation data\nPREP_TRAIN = \"/kaggle/working/train_preprocessed_corn\"\nPREP_VAL = \"/kaggle/working/val_preprocessed_corn\"\nIMG_SIZE = (256, 256)\n\n# âœ… STEP 2: Enhance with CLAHE (modified for Corn subclasses)\ndef enhance_images(src, dst):\n    if not os.path.exists(dst): os.makedirs(dst)\n    for disease_class in os.listdir(src):\n        src_class = os.path.join(src, disease_class)\n        dst_class = os.path.join(dst, disease_class)\n        os.makedirs(dst_class, exist_ok=True)\n        for img in tqdm(os.listdir(src_class), desc=f\"Processing {disease_class}\"):\n            try:\n                path = os.path.join(src_class, img)\n                image = cv2.imread(path)\n                if image is None:\n                    continue\n                image = cv2.resize(image, IMG_SIZE)\n                lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n                l, a, b = cv2.split(lab)\n                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n                cl = clahe.apply(l)\n                limg = cv2.merge((cl, a, b))\n                final = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n                cv2.imwrite(os.path.join(dst_class, img), final)\n            except Exception as e:\n                print(f\"Error processing {path}: {str(e)}\")\n                continue\n\n# âœ… Only run once\nenhance_images(RAW_TRAIN, PREP_TRAIN)\nenhance_images(RAW_VAL, PREP_VAL)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-03T18:55:17.937744Z","iopub.execute_input":"2025-07-03T18:55:17.938339Z","iopub.status.idle":"2025-07-03T18:56:44.041662Z","shell.execute_reply.started":"2025-07-03T18:55:17.938311Z","shell.execute_reply":"2025-07-03T18:56:44.040921Z"}},"outputs":[{"name":"stderr","text":"Processing Corn_Cercospora_leaf_spot Gray_leaf_spot: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2216/2216 [00:18<00:00, 120.35it/s]\nProcessing Corn_(maize)Common_rust: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3213/3213 [00:26<00:00, 122.19it/s]\nProcessing Corn_(maize)Northern_Leaf_Blight: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1908/1908 [00:14<00:00, 135.85it/s]\nProcessing Corn_(maize)healthy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1859/1859 [00:13<00:00, 139.01it/s]\nProcessing Corn_Cercospora_leaf_spot Gray_leaf_spot: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:03<00:00, 135.64it/s]\nProcessing Corn_(maize)Common_rust: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 495/495 [00:04<00:00, 121.87it/s]\nProcessing Corn_(maize)Northern_Leaf_Blight: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [00:03<00:00, 148.76it/s]\nProcessing Corn_(maize)healthy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 465/465 [00:02<00:00, 161.23it/s]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# âœ… STEP 3: Class Check - For Corn disease classes\nassert sorted(os.listdir(PREP_TRAIN)) == sorted(os.listdir(PREP_VAL)), \"Train/Val class mismatch in Corn data\"\nNUM_CLASSES = len(os.listdir(PREP_TRAIN))\nprint(f\"Number of Corn disease classes: {NUM_CLASSES}\")\n\n# âœ… STEP 4: Augmentation\ntrain_gen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=30,\n    zoom_range=0.25,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    brightness_range=(0.8, 1.2),\n    channel_shift_range=20.0,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='nearest'\n)\n\nval_gen = ImageDataGenerator(rescale=1./255)\n\ntrain_data = train_gen.flow_from_directory(\n    PREP_TRAIN, \n    target_size=IMG_SIZE, \n    batch_size=32, \n    class_mode='categorical', \n    shuffle=True,\n    classes=sorted(os.listdir(PREP_TRAIN))  # Ensure consistent class ordering\n)\n\nval_data = val_gen.flow_from_directory(\n    PREP_VAL, \n    target_size=IMG_SIZE, \n    batch_size=32, \n    class_mode='categorical', \n    shuffle=False,\n    classes=sorted(os.listdir(PREP_TRAIN))  # Same classes as training\n)\n\n# âœ… STEP 5: Build Model (Keras built-in)\nbase_model = EfficientNetV2B3(include_top=False, weights='imagenet', input_shape=(256, 256, 3))\nx = GlobalAveragePooling2D()(base_model.output)\nx = Dropout(0.4)(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.3)(x)\noutput = Dense(NUM_CLASSES, activation='softmax')(x)\nmodel = Model(inputs=base_model.input, outputs=output)\n\n# âœ… STEP 6: Compile\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-3),\n    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n    metrics=['accuracy']\n)\n\n# âœ… STEP 7: Callbacks\ncallbacks = [\n    ModelCheckpoint(\"best_corn_model.h5\", save_best_only=True, monitor='val_accuracy'),\n    ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.3, verbose=1),\n    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n]\n\n# âœ… STEP 8: Phase 1 - Train Head\nbase_model.trainable = False\nprint(\"âœ… Phase 1: Training classifier head for Corn diseases...\")\nmodel.fit(train_data, validation_data=val_data, epochs=8, callbacks=callbacks)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-03T18:57:51.479711Z","iopub.execute_input":"2025-07-03T18:57:51.480374Z","iopub.status.idle":"2025-07-03T19:19:57.870641Z","shell.execute_reply.started":"2025-07-03T18:57:51.480345Z","shell.execute_reply":"2025-07-03T19:19:57.870050Z"}},"outputs":[{"name":"stdout","text":"Number of Corn disease classes: 4\nFound 9196 images belonging to 4 classes.\nFound 1867 images belonging to 4 classes.\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1751569072.880982      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1751569072.881615      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b3_notop.h5\n\u001b[1m52606240/52606240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nâœ… Phase 1: Training classifier head for Corn diseases...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/8\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1751569104.828591     114 service.cc:148] XLA service 0x7f53d0002370 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1751569104.829425     114 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1751569104.829445     114 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1751569107.872362     114 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  1/288\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3:49:29\u001b[0m 48s/step - accuracy: 0.1875 - loss: 1.4436","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1751569125.633483     114 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 651ms/step - accuracy: 0.3142 - loss: 1.4089 - val_accuracy: 0.2651 - val_loss: 1.4048 - learning_rate: 0.0010\nEpoch 2/8\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 537ms/step - accuracy: 0.3278 - loss: 1.3711 - val_accuracy: 0.2651 - val_loss: 1.3846 - learning_rate: 0.0010\nEpoch 3/8\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 539ms/step - accuracy: 0.3539 - loss: 1.3642 - val_accuracy: 0.2732 - val_loss: 1.3842 - learning_rate: 0.0010\nEpoch 4/8\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 539ms/step - accuracy: 0.3514 - loss: 1.3608 - val_accuracy: 0.2753 - val_loss: 1.3674 - learning_rate: 0.0010\nEpoch 5/8\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 534ms/step - accuracy: 0.3608 - loss: 1.3556 - val_accuracy: 0.2694 - val_loss: 1.3737 - learning_rate: 0.0010\nEpoch 6/8\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527ms/step - accuracy: 0.3683 - loss: 1.3512\nEpoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 545ms/step - accuracy: 0.3683 - loss: 1.3512 - val_accuracy: 0.2855 - val_loss: 1.3676 - learning_rate: 0.0010\nEpoch 7/8\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 536ms/step - accuracy: 0.3613 - loss: 1.3544 - val_accuracy: 0.2839 - val_loss: 1.3713 - learning_rate: 3.0000e-04\nEpoch 8/8\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 536ms/step - accuracy: 0.3739 - loss: 1.3434 - val_accuracy: 0.3192 - val_loss: 1.3592 - learning_rate: 3.0000e-04\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7f54a01cf5d0>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# âœ… STEP 9: Phase 2 - Fine-tune All\nbase_model.trainable = True\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-5),\n    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n    metrics=['accuracy']\n)\nprint(\"âœ… Phase 2: Fine-tuning full model for Corn diseases...\")\nhistory = model.fit(train_data, validation_data=val_data, epochs=20, callbacks=callbacks)\n\n# âœ… STEP 10: Evaluation\nval_loss, val_acc = model.evaluate(val_data)\nprint(f\"\\nâœ… Final Validation Accuracy for Corn diseases: {val_acc:.4f}\")\nprint(f\"ğŸ”» Final Validation Loss for Corn diseases: {val_loss:.4f}\")\n\n# Print class indices for reference\nprint(\"\\nClass Indices:\", train_data.class_indices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-03T19:20:54.955455Z","iopub.execute_input":"2025-07-03T19:20:54.955738Z","iopub.status.idle":"2025-07-03T20:20:18.317508Z","shell.execute_reply.started":"2025-07-03T19:20:54.955717Z","shell.execute_reply":"2025-07-03T20:20:18.316753Z"}},"outputs":[{"name":"stdout","text":"âœ… Phase 2: Fine-tuning full model for Corn diseases...\nEpoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1751570570.601201     115 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1751570570.747361     115 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1751570571.276455     115 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1751570571.428488     115 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1751570571.917060     115 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1751570572.067874     115 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1751570572.216074     115 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  4/288\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m2:16\u001b[0m 480ms/step - accuracy: 0.1914 - loss: 1.6583","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1751570623.950587     115 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1751570624.088733     115 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1751570624.466131     115 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1751570624.607511     115 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 828ms/step - accuracy: 0.4054 - loss: 1.3380 - val_accuracy: 0.7327 - val_loss: 0.8812 - learning_rate: 1.0000e-05\nEpoch 2/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 578ms/step - accuracy: 0.7807 - loss: 0.8128 - val_accuracy: 0.8848 - val_loss: 0.6023 - learning_rate: 1.0000e-05\nEpoch 3/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 581ms/step - accuracy: 0.8653 - loss: 0.6452 - val_accuracy: 0.9239 - val_loss: 0.5229 - learning_rate: 1.0000e-05\nEpoch 4/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 577ms/step - accuracy: 0.9026 - loss: 0.5883 - val_accuracy: 0.9389 - val_loss: 0.4983 - learning_rate: 1.0000e-05\nEpoch 5/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 579ms/step - accuracy: 0.9090 - loss: 0.5654 - val_accuracy: 0.9432 - val_loss: 0.4829 - learning_rate: 1.0000e-05\nEpoch 6/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 578ms/step - accuracy: 0.9206 - loss: 0.5450 - val_accuracy: 0.9464 - val_loss: 0.4739 - learning_rate: 1.0000e-05\nEpoch 7/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 577ms/step - accuracy: 0.9332 - loss: 0.5223 - val_accuracy: 0.9545 - val_loss: 0.4558 - learning_rate: 1.0000e-05\nEpoch 8/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 583ms/step - accuracy: 0.9390 - loss: 0.5087 - val_accuracy: 0.9582 - val_loss: 0.4456 - learning_rate: 1.0000e-05\nEpoch 9/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 577ms/step - accuracy: 0.9404 - loss: 0.5032 - val_accuracy: 0.9641 - val_loss: 0.4374 - learning_rate: 1.0000e-05\nEpoch 10/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 575ms/step - accuracy: 0.9412 - loss: 0.4949 - val_accuracy: 0.9673 - val_loss: 0.4285 - learning_rate: 1.0000e-05\nEpoch 11/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 576ms/step - accuracy: 0.9536 - loss: 0.4738 - val_accuracy: 0.9668 - val_loss: 0.4284 - learning_rate: 1.0000e-05\nEpoch 12/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 580ms/step - accuracy: 0.9470 - loss: 0.4823 - val_accuracy: 0.9657 - val_loss: 0.4259 - learning_rate: 1.0000e-05\nEpoch 13/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 577ms/step - accuracy: 0.9549 - loss: 0.4690 - val_accuracy: 0.9711 - val_loss: 0.4161 - learning_rate: 1.0000e-05\nEpoch 14/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 576ms/step - accuracy: 0.9601 - loss: 0.4543 - val_accuracy: 0.9668 - val_loss: 0.4191 - learning_rate: 1.0000e-05\nEpoch 15/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558ms/step - accuracy: 0.9643 - loss: 0.4506\nEpoch 15: ReduceLROnPlateau reducing learning rate to 2.9999999242136253e-06.\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 575ms/step - accuracy: 0.9643 - loss: 0.4506 - val_accuracy: 0.9705 - val_loss: 0.4161 - learning_rate: 1.0000e-05\nEpoch 16/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 585ms/step - accuracy: 0.9635 - loss: 0.4492 - val_accuracy: 0.9716 - val_loss: 0.4121 - learning_rate: 3.0000e-06\nEpoch 17/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 581ms/step - accuracy: 0.9652 - loss: 0.4452 - val_accuracy: 0.9732 - val_loss: 0.4079 - learning_rate: 3.0000e-06\nEpoch 18/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 579ms/step - accuracy: 0.9637 - loss: 0.4467 - val_accuracy: 0.9743 - val_loss: 0.4092 - learning_rate: 3.0000e-06\nEpoch 19/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step - accuracy: 0.9657 - loss: 0.4435\nEpoch 19: ReduceLROnPlateau reducing learning rate to 8.999999636216671e-07.\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 582ms/step - accuracy: 0.9657 - loss: 0.4435 - val_accuracy: 0.9754 - val_loss: 0.4092 - learning_rate: 3.0000e-06\nEpoch 20/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 576ms/step - accuracy: 0.9694 - loss: 0.4397 - val_accuracy: 0.9748 - val_loss: 0.4066 - learning_rate: 9.0000e-07\n\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.9734 - loss: 0.4074\n\nâœ… Final Validation Accuracy for Corn diseases: 0.9748\nğŸ”» Final Validation Loss for Corn diseases: 0.4066\n\nClass Indices: {'Corn_(maize)Common_rust': 0, 'Corn_(maize)Northern_Leaf_Blight': 1, 'Corn_(maize)healthy': 2, 'Corn_Cercospora_leaf_spot Gray_leaf_spot': 3}\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import os, cv2, numpy as np\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetV2B3\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\n# âœ… Configuration\nBASE = \"/kaggle/input/team-11a-crop-wise-dataset/Dataset_annam\"\nIMG_SIZE = (256, 256)\nCROPS = ['Corn', 'Cotton', 'Grape', 'Potato', 'Rice', 'Sugarcane', 'Tomato', 'Wheat']  # Note: 'Cotton' was misspelled as 'Cotton' in your original structure\n\n# First, let's verify the actual dataset structure\nprint(\"Available directories in dataset root:\")\nprint(os.listdir(BASE))\n\n# âœ… Function to train model for a single crop\ndef train_crop_model(crop_name):\n    print(f\"\\n{'='*50}\")\n    print(f\"ğŸš€ Starting training for {crop_name} crop\")\n    print(f\"{'='*50}\\n\")\n    \n    # Updated paths based on your dataset structure\n    raw_train = os.path.join(BASE, crop_name, \"Train\")\n    raw_val = os.path.join(BASE, crop_name, \"Valid\")\n    \n    # Verify paths exist\n    if not os.path.exists(raw_train):\n        print(f\"âŒ Training directory not found: {raw_train}\")\n        return None\n    if not os.path.exists(raw_val):\n        print(f\"âŒ Validation directory not found: {raw_val}\")\n        return None\n    \n    prep_train = f\"/kaggle/working/train_preprocessed_{crop_name.lower()}\"\n    prep_val = f\"/kaggle/working/val_preprocessed_{crop_name.lower()}\"\n    \n    # âœ… Preprocessing\n    def enhance_images(src, dst):\n        if not os.path.exists(dst): os.makedirs(dst)\n        for disease_class in os.listdir(src):\n            src_class = os.path.join(src, disease_class)\n            dst_class = os.path.join(dst, disease_class)\n            os.makedirs(dst_class, exist_ok=True)\n            for img in tqdm(os.listdir(src_class), desc=f\"Processing {disease_class}\"):\n                try:\n                    path = os.path.join(src_class, img)\n                    image = cv2.imread(path)\n                    if image is None:\n                        continue\n                    image = cv2.resize(image, IMG_SIZE)\n                    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n                    l, a, b = cv2.split(lab)\n                    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n                    cl = clahe.apply(l)\n                    limg = cv2.merge((cl, a, b))\n                    final = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n                    cv2.imwrite(os.path.join(dst_class, img), final)\n                except Exception as e:\n                    print(f\"Error processing {path}: {str(e)}\")\n                    continue\n    \n    # Run preprocessing\n    print(\"Preprocessing training data...\")\n    enhance_images(raw_train, prep_train)\n    print(\"Preprocessing validation data...\")\n    enhance_images(raw_val, prep_val)\n    \n    # Verify classes\n    try:\n        assert sorted(os.listdir(prep_train)) == sorted(os.listdir(prep_val)), f\"Train/Val class mismatch in {crop_name} data\"\n        num_classes = len(os.listdir(prep_train))\n        print(f\"Number of {crop_name} disease classes: {num_classes}\")\n    except Exception as e:\n        print(f\"âŒ Error verifying classes: {str(e)}\")\n        return None\n    \n    # Data generators\n    train_gen = ImageDataGenerator(\n        rescale=1./255,\n        rotation_range=30,\n        zoom_range=0.25,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.15,\n        brightness_range=(0.8, 1.2),\n        channel_shift_range=20.0,\n        horizontal_flip=True,\n        vertical_flip=True,\n        fill_mode='nearest'\n    )\n    \n    val_gen = ImageDataGenerator(rescale=1./255)\n    \n    train_data = train_gen.flow_from_directory(\n        prep_train,\n        target_size=IMG_SIZE,\n        batch_size=32,\n        class_mode='categorical',\n        shuffle=True,\n        classes=sorted(os.listdir(prep_train))\n    )\n    \n    val_data = val_gen.flow_from_directory(\n        prep_val,\n        target_size=IMG_SIZE,\n        batch_size=32,\n        class_mode='categorical',\n        shuffle=False,\n        classes=sorted(os.listdir(prep_train))\n    )\n    \n    # Model architecture\n    base_model = EfficientNetV2B3(include_top=False, weights='imagenet', input_shape=(256, 256, 3))\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = Dropout(0.4)(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.3)(x)\n    output = Dense(num_classes, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=output)\n    \n    # Compile\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(1e-3),\n        loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n        metrics=['accuracy']\n    )\n    \n    # Callbacks\n    callbacks = [\n        ModelCheckpoint(f\"best_{crop_name.lower()}_model.h5\", save_best_only=True, monitor='val_accuracy'),\n        ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.3, verbose=1),\n        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    ]\n    \n    # Training\n    print(f\"\\nâœ… Phase 1: Training classifier head for {crop_name} diseases...\")\n    base_model.trainable = False\n    model.fit(train_data, validation_data=val_data, epochs=8, callbacks=callbacks)\n    \n    print(f\"\\nâœ… Phase 2: Fine-tuning full model for {crop_name} diseases...\")\n    base_model.trainable = True\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(1e-5),\n        loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n        metrics=['accuracy']\n    )\n    history = model.fit(train_data, validation_data=val_data, epochs=20, callbacks=callbacks)\n    \n    # Evaluation\n    val_loss, val_acc = model.evaluate(val_data)\n    print(f\"\\nâœ… Final Validation Accuracy for {crop_name}: {val_acc:.4f}\")\n    print(f\"ğŸ”» Final Validation Loss for {crop_name}: {val_loss:.4f}\")\n    print(\"\\nClass Indices:\", train_data.class_indices)\n    \n    return val_acc\n\n# âœ… Train models for all crops\nresults = {}\nfor crop in CROPS:\n    try:\n        acc = train_crop_model(crop)\n        results[crop] = acc\n    except Exception as e:\n        print(f\"âŒ Error processing {crop}: {str(e)}\")\n        results[crop] = None\n\n# âœ… Print summary of all results\nprint(\"\\n\\n=== FINAL RESULTS ===\")\nfor crop, acc in results.items():\n    if acc is not None:\n        print(f\"{crop}: {acc:.4f} validation accuracy\")\n    else:\n        print(f\"{crop}: Failed to train model\")\n\nprint(\"\\nTraining completed for all crops!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-03T20:50:12.208789Z","iopub.execute_input":"2025-07-03T20:50:12.209500Z"}},"outputs":[{"name":"stdout","text":"Available directories in dataset root:\n['Tomato', 'Wheat', 'Sugarcane', 'Corn', 'Cotton', 'Grape', 'Rice', 'Potato']\n\n==================================================\nğŸš€ Starting training for Corn crop\n==================================================\n\nPreprocessing training data...\n","output_type":"stream"},{"name":"stderr","text":"Processing Corn_Cercospora_leaf_spot Gray_leaf_spot: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2216/2216 [00:13<00:00, 164.93it/s]\nProcessing Corn_(maize)Common_rust: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3213/3213 [00:19<00:00, 163.90it/s]\nProcessing Corn_(maize)Northern_Leaf_Blight: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1908/1908 [00:10<00:00, 181.49it/s]\nProcessing Corn_(maize)healthy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1859/1859 [00:09<00:00, 186.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Preprocessing validation data...\n","output_type":"stream"},{"name":"stderr","text":"Processing Corn_Cercospora_leaf_spot Gray_leaf_spot: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:02<00:00, 165.36it/s]\nProcessing Corn_(maize)Common_rust: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 495/495 [00:02<00:00, 168.04it/s]\nProcessing Corn_(maize)Northern_Leaf_Blight: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [00:02<00:00, 177.25it/s]\nProcessing Corn_(maize)healthy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 465/465 [00:02<00:00, 177.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Number of Corn disease classes: 4\nFound 9196 images belonging to 4 classes.\nFound 1867 images belonging to 4 classes.\n\nâœ… Phase 1: Training classifier head for Corn diseases...\nEpoch 1/8\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 653ms/step - accuracy: 0.2971 - loss: 1.4103 - val_accuracy: 0.2651 - val_loss: 1.4321 - learning_rate: 0.0010\nEpoch 2/8\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 553ms/step - accuracy: 0.3553 - loss: 1.3671 - val_accuracy: 0.3637 - val_loss: 1.3913 - learning_rate: 0.0010\nEpoch 3/8\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 538ms/step - accuracy: 0.3584 - loss: 1.3631 - val_accuracy: 0.2817 - val_loss: 1.3780 - learning_rate: 0.0010\nEpoch 4/8\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 546ms/step - accuracy: 0.3477 - loss: 1.3629 - val_accuracy: 0.3235 - val_loss: 1.3669 - learning_rate: 0.0010\nEpoch 5/8\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 537ms/step - accuracy: 0.3645 - loss: 1.3577 - val_accuracy: 0.3091 - val_loss: 1.3782 - learning_rate: 0.0010\nEpoch 6/8\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519ms/step - accuracy: 0.3668 - loss: 1.3540\nEpoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 535ms/step - accuracy: 0.3667 - loss: 1.3540 - val_accuracy: 0.2941 - val_loss: 1.3752 - learning_rate: 0.0010\nEpoch 7/8\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 537ms/step - accuracy: 0.3708 - loss: 1.3493 - val_accuracy: 0.2999 - val_loss: 1.3628 - learning_rate: 3.0000e-04\nEpoch 8/8\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 537ms/step - accuracy: 0.3858 - loss: 1.3438 - val_accuracy: 0.3171 - val_loss: 1.3549 - learning_rate: 3.0000e-04\n\nâœ… Phase 2: Fine-tuning full model for Corn diseases...\nEpoch 1/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 784ms/step - accuracy: 0.4135 - loss: 1.3515 - val_accuracy: 0.8093 - val_loss: 0.8425 - learning_rate: 1.0000e-05\nEpoch 2/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 576ms/step - accuracy: 0.7828 - loss: 0.8195 - val_accuracy: 0.8982 - val_loss: 0.5865 - learning_rate: 1.0000e-05\nEpoch 3/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 573ms/step - accuracy: 0.8620 - loss: 0.6503 - val_accuracy: 0.9309 - val_loss: 0.5191 - learning_rate: 1.0000e-05\nEpoch 4/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 566ms/step - accuracy: 0.8992 - loss: 0.5834 - val_accuracy: 0.9422 - val_loss: 0.4934 - learning_rate: 1.0000e-05\nEpoch 5/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 588ms/step - accuracy: 0.9185 - loss: 0.5560 - val_accuracy: 0.9475 - val_loss: 0.4814 - learning_rate: 1.0000e-05\nEpoch 6/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 576ms/step - accuracy: 0.9213 - loss: 0.5433 - val_accuracy: 0.9577 - val_loss: 0.4591 - learning_rate: 1.0000e-05\nEpoch 7/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 585ms/step - accuracy: 0.9291 - loss: 0.5262 - val_accuracy: 0.9630 - val_loss: 0.4504 - learning_rate: 1.0000e-05\nEpoch 8/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 567ms/step - accuracy: 0.9400 - loss: 0.5030 - val_accuracy: 0.9625 - val_loss: 0.4440 - learning_rate: 1.0000e-05\nEpoch 9/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 571ms/step - accuracy: 0.9466 - loss: 0.4912 - val_accuracy: 0.9625 - val_loss: 0.4388 - learning_rate: 1.0000e-05\nEpoch 10/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 574ms/step - accuracy: 0.9484 - loss: 0.4901 - val_accuracy: 0.9716 - val_loss: 0.4258 - learning_rate: 1.0000e-05\nEpoch 11/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 570ms/step - accuracy: 0.9563 - loss: 0.4719 - val_accuracy: 0.9700 - val_loss: 0.4234 - learning_rate: 1.0000e-05\nEpoch 12/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 578ms/step - accuracy: 0.9564 - loss: 0.4712 - val_accuracy: 0.9727 - val_loss: 0.4194 - learning_rate: 1.0000e-05\nEpoch 13/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 579ms/step - accuracy: 0.9550 - loss: 0.4596 - val_accuracy: 0.9754 - val_loss: 0.4107 - learning_rate: 1.0000e-05\nEpoch 14/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 579ms/step - accuracy: 0.9608 - loss: 0.4578 - val_accuracy: 0.9796 - val_loss: 0.4042 - learning_rate: 1.0000e-05\nEpoch 15/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 571ms/step - accuracy: 0.9654 - loss: 0.4506 - val_accuracy: 0.9764 - val_loss: 0.4060 - learning_rate: 1.0000e-05\nEpoch 16/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 590ms/step - accuracy: 0.9656 - loss: 0.4419 - val_accuracy: 0.9791 - val_loss: 0.4030 - learning_rate: 1.0000e-05\nEpoch 17/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 566ms/step - accuracy: 0.9695 - loss: 0.4363 - val_accuracy: 0.9770 - val_loss: 0.4037 - learning_rate: 1.0000e-05\nEpoch 18/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 576ms/step - accuracy: 0.9728 - loss: 0.4291 - val_accuracy: 0.9786 - val_loss: 0.3961 - learning_rate: 1.0000e-05\nEpoch 19/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 576ms/step - accuracy: 0.9683 - loss: 0.4348 - val_accuracy: 0.9802 - val_loss: 0.3969 - learning_rate: 1.0000e-05\nEpoch 20/20\n\u001b[1m288/288\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 571ms/step - accuracy: 0.9701 - loss: 0.4314 - val_accuracy: 0.9802 - val_loss: 0.3893 - learning_rate: 1.0000e-05\n\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.9752 - loss: 0.3933\n\nâœ… Final Validation Accuracy for Corn: 0.9802\nğŸ”» Final Validation Loss for Corn: 0.3893\n\nClass Indices: {'Corn_(maize)Common_rust': 0, 'Corn_(maize)Northern_Leaf_Blight': 1, 'Corn_(maize)healthy': 2, 'Corn_Cercospora_leaf_spot Gray_leaf_spot': 3}\n\n==================================================\nğŸš€ Starting training for Cotton crop\n==================================================\n\nPreprocessing training data...\n","output_type":"stream"},{"name":"stderr","text":"Processing Powdery mildew: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 800/800 [00:14<00:00, 56.53it/s]\nProcessing Army worm: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 800/800 [00:13<00:00, 59.86it/s]\nProcessing Bacterial blight:  33%|â–ˆâ–ˆâ–ˆâ–      | 409/1250 [00:06<00:13, 64.42it/s]libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\nProcessing Bacterial blight:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 849/1250 [00:13<00:06, 65.27it/s]libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\nProcessing Bacterial blight: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1250/1250 [00:19<00:00, 63.47it/s]\nProcessing Healthy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1226/1226 [00:19<00:00, 64.10it/s]\nProcessing Target spot: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 788/788 [00:13<00:00, 60.07it/s]\nProcessing Aphids: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 800/800 [00:14<00:00, 53.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Preprocessing validation data...\n","output_type":"stream"},{"name":"stderr","text":"Processing Powdery mildew: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:00<00:00, 61.78it/s]\nProcessing Army worm: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 65.04it/s]\nProcessing Bacterial blight: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 284/284 [00:04<00:00, 69.95it/s]\nProcessing Healthy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 177/177 [00:02<00:00, 65.80it/s]\nProcessing Target spot: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:00<00:00, 62.41it/s]\nProcessing Aphids: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 287/287 [00:05<00:00, 52.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Number of Cotton disease classes: 6\nFound 5663 images belonging to 6 classes.\nFound 867 images belonging to 6 classes.\n\nâœ… Phase 1: Training classifier head for Cotton diseases...\nEpoch 1/8\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 734ms/step - accuracy: 0.2111 - loss: 1.8221 - val_accuracy: 0.3783 - val_loss: 1.6673 - learning_rate: 0.0010\nEpoch 2/8\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 540ms/step - accuracy: 0.2416 - loss: 1.7585 - val_accuracy: 0.2572 - val_loss: 1.7620 - learning_rate: 0.0010\nEpoch 3/8\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 536ms/step - accuracy: 0.2554 - loss: 1.7366 - val_accuracy: 0.3518 - val_loss: 1.6576 - learning_rate: 0.0010\nEpoch 4/8\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 539ms/step - accuracy: 0.2579 - loss: 1.7331 - val_accuracy: 0.3414 - val_loss: 1.6592 - learning_rate: 0.0010\nEpoch 5/8\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521ms/step - accuracy: 0.2700 - loss: 1.7278\nEpoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 534ms/step - accuracy: 0.2700 - loss: 1.7277 - val_accuracy: 0.2330 - val_loss: 1.7128 - learning_rate: 0.0010\nEpoch 6/8\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 536ms/step - accuracy: 0.2752 - loss: 1.7235 - val_accuracy: 0.2791 - val_loss: 1.6861 - learning_rate: 3.0000e-04\nEpoch 7/8\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520ms/step - accuracy: 0.2802 - loss: 1.7228\nEpoch 7: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 533ms/step - accuracy: 0.2802 - loss: 1.7228 - val_accuracy: 0.2953 - val_loss: 1.6740 - learning_rate: 3.0000e-04\nEpoch 8/8\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 542ms/step - accuracy: 0.2858 - loss: 1.7143 - val_accuracy: 0.3195 - val_loss: 1.6505 - learning_rate: 9.0000e-05\n\nâœ… Phase 2: Fine-tuning full model for Cotton diseases...\nEpoch 1/20\n\u001b[1m 75/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m56s\u001b[0m 555ms/step - accuracy: 0.2328 - loss: 2.0142","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1751581894.887546     116 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1751581895.034008     116 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1751581895.546627     116 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1751581895.697619     116 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1751581896.152214     116 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1751581896.300546     116 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 954ms/step - accuracy: 0.2567 - loss: 1.9216 - val_accuracy: 0.4221 - val_loss: 1.4805 - learning_rate: 1.0000e-05\nEpoch 2/20\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 593ms/step - accuracy: 0.4162 - loss: 1.5560 - val_accuracy: 0.5213 - val_loss: 1.2815 - learning_rate: 1.0000e-05\nEpoch 3/20\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 578ms/step - accuracy: 0.5176 - loss: 1.3811 - val_accuracy: 0.6448 - val_loss: 1.1416 - learning_rate: 1.0000e-05\nEpoch 4/20\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 578ms/step - accuracy: 0.6176 - loss: 1.2130 - val_accuracy: 0.7589 - val_loss: 1.0109 - learning_rate: 1.0000e-05\nEpoch 5/20\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 584ms/step - accuracy: 0.6834 - loss: 1.1010 - val_accuracy: 0.8397 - val_loss: 0.8898 - learning_rate: 1.0000e-05\nEpoch 6/20\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 579ms/step - accuracy: 0.7539 - loss: 0.9881 - val_accuracy: 0.8639 - val_loss: 0.8030 - learning_rate: 1.0000e-05\nEpoch 7/20\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 579ms/step - accuracy: 0.7946 - loss: 0.9124 - val_accuracy: 0.9193 - val_loss: 0.7209 - learning_rate: 1.0000e-05\nEpoch 8/20\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 580ms/step - accuracy: 0.8200 - loss: 0.8623 - val_accuracy: 0.9273 - val_loss: 0.6719 - learning_rate: 1.0000e-05\nEpoch 9/20\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 586ms/step - accuracy: 0.8369 - loss: 0.8154 - val_accuracy: 0.9319 - val_loss: 0.6464 - learning_rate: 1.0000e-05\nEpoch 10/20\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 580ms/step - accuracy: 0.8516 - loss: 0.7874 - val_accuracy: 0.9354 - val_loss: 0.6300 - learning_rate: 1.0000e-05\nEpoch 11/20\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 582ms/step - accuracy: 0.8720 - loss: 0.7550 - val_accuracy: 0.9435 - val_loss: 0.6095 - learning_rate: 1.0000e-05\nEpoch 12/20\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 583ms/step - accuracy: 0.8873 - loss: 0.7168 - val_accuracy: 0.9458 - val_loss: 0.6050 - learning_rate: 1.0000e-05\nEpoch 13/20\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 568ms/step - accuracy: 0.8846 - loss: 0.7241 - val_accuracy: 0.9423 - val_loss: 0.5945 - learning_rate: 1.0000e-05\nEpoch 14/20\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 575ms/step - accuracy: 0.9071 - loss: 0.6765 - val_accuracy: 0.9539 - val_loss: 0.5745 - learning_rate: 1.0000e-05\nEpoch 15/20\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 583ms/step - accuracy: 0.9163 - loss: 0.6669 - val_accuracy: 0.9550 - val_loss: 0.5666 - learning_rate: 1.0000e-05\nEpoch 16/20\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 586ms/step - accuracy: 0.9167 - loss: 0.6526 - val_accuracy: 0.9596 - val_loss: 0.5579 - learning_rate: 1.0000e-05\nEpoch 17/20\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 582ms/step - accuracy: 0.9312 - loss: 0.6307 - val_accuracy: 0.9608 - val_loss: 0.5503 - learning_rate: 1.0000e-05\nEpoch 18/20\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 579ms/step - accuracy: 0.9304 - loss: 0.6174 - val_accuracy: 0.9619 - val_loss: 0.5441 - learning_rate: 1.0000e-05\nEpoch 19/20\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 572ms/step - accuracy: 0.9427 - loss: 0.6022 - val_accuracy: 0.9619 - val_loss: 0.5366 - learning_rate: 1.0000e-05\nEpoch 20/20\n\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 597ms/step - accuracy: 0.9374 - loss: 0.6137 - val_accuracy: 0.9642 - val_loss: 0.5374 - learning_rate: 1.0000e-05\n\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.9603 - loss: 0.5536\n\nâœ… Final Validation Accuracy for Cotton: 0.9619\nğŸ”» Final Validation Loss for Cotton: 0.5366\n\nClass Indices: {'Aphids': 0, 'Army worm': 1, 'Bacterial blight': 2, 'Healthy': 3, 'Powdery mildew': 4, 'Target spot': 5}\n\n==================================================\nğŸš€ Starting training for Grape crop\n==================================================\n\nPreprocessing training data...\n","output_type":"stream"},{"name":"stderr","text":"Processing Grape___healthy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1692/1692 [00:18<00:00, 92.60it/s]\nProcessing Grape___Leaf_blight_(Isariopsis_Leaf_Spot): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1722/1722 [00:19<00:00, 87.74it/s]\nProcessing Grape___Black_rot: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1888/1888 [00:20<00:00, 91.76it/s]\nProcessing Grape___Esca_(Black_Measles): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1920/1920 [00:22<00:00, 83.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"Preprocessing validation data...\n","output_type":"stream"},{"name":"stderr","text":"Processing Grape___healthy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 423/423 [00:03<00:00, 115.41it/s]\nProcessing Grape___Leaf_blight_(Isariopsis_Leaf_Spot): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:04<00:00, 105.29it/s]\nProcessing Grape___Black_rot: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 472/472 [00:04<00:00, 111.38it/s]\nProcessing Grape___Esca_(Black_Measles): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 480/480 [00:04<00:00, 105.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Number of Grape disease classes: 4\nFound 7222 images belonging to 4 classes.\nFound 1805 images belonging to 4 classes.\n\nâœ… Phase 1: Training classifier head for Grape diseases...\nEpoch 1/8\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 690ms/step - accuracy: 0.2672 - loss: 1.4251 - val_accuracy: 0.2659 - val_loss: 1.3768 - learning_rate: 0.0010\nEpoch 2/8\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 545ms/step - accuracy: 0.2733 - loss: 1.3869 - val_accuracy: 0.3474 - val_loss: 1.3771 - learning_rate: 0.0010\nEpoch 3/8\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 541ms/step - accuracy: 0.2693 - loss: 1.3852 - val_accuracy: 0.2670 - val_loss: 1.3714 - learning_rate: 0.0010\nEpoch 4/8\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 539ms/step - accuracy: 0.2822 - loss: 1.3799 - val_accuracy: 0.4720 - val_loss: 1.3654 - learning_rate: 0.0010\nEpoch 5/8\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 544ms/step - accuracy: 0.2919 - loss: 1.3794 - val_accuracy: 0.3906 - val_loss: 1.3641 - learning_rate: 0.0010\nEpoch 6/8\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 541ms/step - accuracy: 0.3050 - loss: 1.3724 - val_accuracy: 0.4161 - val_loss: 1.3502 - learning_rate: 0.0010\nEpoch 7/8\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 539ms/step - accuracy: 0.2953 - loss: 1.3755 - val_accuracy: 0.4454 - val_loss: 1.3513 - learning_rate: 0.0010\nEpoch 8/8\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518ms/step - accuracy: 0.3036 - loss: 1.3722\nEpoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 539ms/step - accuracy: 0.3036 - loss: 1.3722 - val_accuracy: 0.4238 - val_loss: 1.3516 - learning_rate: 0.0010\n\nâœ… Phase 2: Fine-tuning full model for Grape diseases...\nEpoch 1/20\n\u001b[1m201/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m13s\u001b[0m 554ms/step - accuracy: 0.4238 - loss: 1.3499","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1751585397.075917     115 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1751585397.218136     115 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1751585397.669629     115 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1751585397.815576     115 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 884ms/step - accuracy: 0.4389 - loss: 1.3288 - val_accuracy: 0.8521 - val_loss: 0.7149 - learning_rate: 1.0000e-05\nEpoch 2/20\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 594ms/step - accuracy: 0.8226 - loss: 0.7525 - val_accuracy: 0.9435 - val_loss: 0.5094 - learning_rate: 1.0000e-05\nEpoch 3/20\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 578ms/step - accuracy: 0.9124 - loss: 0.5811 - val_accuracy: 0.9762 - val_loss: 0.4466 - learning_rate: 1.0000e-05\nEpoch 4/20\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 583ms/step - accuracy: 0.9471 - loss: 0.5096 - val_accuracy: 0.9817 - val_loss: 0.4255 - learning_rate: 1.0000e-05\nEpoch 5/20\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 583ms/step - accuracy: 0.9551 - loss: 0.4896 - val_accuracy: 0.9972 - val_loss: 0.4009 - learning_rate: 1.0000e-05\nEpoch 6/20\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 581ms/step - accuracy: 0.9662 - loss: 0.4773 - val_accuracy: 0.9939 - val_loss: 0.3942 - learning_rate: 1.0000e-05\nEpoch 7/20\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 570ms/step - accuracy: 0.9724 - loss: 0.4568 - val_accuracy: 0.9939 - val_loss: 0.3888 - learning_rate: 1.0000e-05\nEpoch 8/20\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 578ms/step - accuracy: 0.9789 - loss: 0.4416 - val_accuracy: 0.9994 - val_loss: 0.3811 - learning_rate: 1.0000e-05\nEpoch 9/20\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 578ms/step - accuracy: 0.9758 - loss: 0.4401 - val_accuracy: 0.9994 - val_loss: 0.3758 - learning_rate: 1.0000e-05\nEpoch 10/20\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 571ms/step - accuracy: 0.9852 - loss: 0.4227 - val_accuracy: 0.9972 - val_loss: 0.3761 - learning_rate: 1.0000e-05\nEpoch 11/20\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 578ms/step - accuracy: 0.9850 - loss: 0.4188 - val_accuracy: 0.9983 - val_loss: 0.3723 - learning_rate: 1.0000e-05\nEpoch 12/20\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 574ms/step - accuracy: 0.9878 - loss: 0.4145 - val_accuracy: 0.9994 - val_loss: 0.3684 - learning_rate: 1.0000e-05\nEpoch 13/20\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 600ms/step - accuracy: 0.9884 - loss: 0.4118 - val_accuracy: 1.0000 - val_loss: 0.3658 - learning_rate: 1.0000e-05\nEpoch 14/20\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 562ms/step - accuracy: 0.9915 - loss: 0.4036 - val_accuracy: 1.0000 - val_loss: 0.3646 - learning_rate: 1.0000e-05\nEpoch 15/20\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 573ms/step - accuracy: 0.9858 - loss: 0.4093 - val_accuracy: 1.0000 - val_loss: 0.3625 - learning_rate: 1.0000e-05\nEpoch 16/20\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 573ms/step - accuracy: 0.9926 - loss: 0.3970 - val_accuracy: 1.0000 - val_loss: 0.3624 - learning_rate: 1.0000e-05\nEpoch 17/20\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 575ms/step - accuracy: 0.9919 - loss: 0.3959 - val_accuracy: 1.0000 - val_loss: 0.3606 - learning_rate: 1.0000e-05\nEpoch 18/20\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 578ms/step - accuracy: 0.9924 - loss: 0.3938 - val_accuracy: 1.0000 - val_loss: 0.3597 - learning_rate: 1.0000e-05\nEpoch 19/20\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 577ms/step - accuracy: 0.9913 - loss: 0.3951 - val_accuracy: 1.0000 - val_loss: 0.3575 - learning_rate: 1.0000e-05\nEpoch 20/20\n\u001b[1m226/226\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 580ms/step - accuracy: 0.9947 - loss: 0.3882 - val_accuracy: 1.0000 - val_loss: 0.3571 - learning_rate: 1.0000e-05\n\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 0.3573\n\nâœ… Final Validation Accuracy for Grape: 1.0000\nğŸ”» Final Validation Loss for Grape: 0.3571\n\nClass Indices: {'Grape___Black_rot': 0, 'Grape___Esca_(Black_Measles)': 1, 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)': 2, 'Grape___healthy': 3}\n\n==================================================\nğŸš€ Starting training for Potato crop\n==================================================\n\nPreprocessing training data...\n","output_type":"stream"},{"name":"stderr","text":"Processing Potato___healthy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1824/1824 [00:20<00:00, 86.88it/s]\nProcessing Potato___Late_blight: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1939/1939 [00:21<00:00, 92.13it/s]\nProcessing Potato___Early_blight: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1939/1939 [00:22<00:00, 85.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Preprocessing validation data...\n","output_type":"stream"},{"name":"stderr","text":"Processing Potato___healthy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [00:04<00:00, 105.03it/s]\nProcessing Potato___Late_blight: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 485/485 [00:04<00:00, 114.58it/s]\nProcessing Potato___Early_blight: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 485/485 [00:04<00:00, 102.67it/s]","output_type":"stream"},{"name":"stdout","text":"Number of Potato disease classes: 3\nFound 5702 images belonging to 3 classes.\nFound 1426 images belonging to 3 classes.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\nâœ… Phase 1: Training classifier head for Potato diseases...\nEpoch 1/8\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 732ms/step - accuracy: 0.3477 - loss: 1.1416 - val_accuracy: 0.4607 - val_loss: 1.0949 - learning_rate: 0.0010\nEpoch 2/8\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 539ms/step - accuracy: 0.3616 - loss: 1.1005 - val_accuracy: 0.3331 - val_loss: 1.0910 - learning_rate: 0.0010\nEpoch 3/8\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 560ms/step - accuracy: 0.3633 - loss: 1.1004 - val_accuracy: 0.3401 - val_loss: 1.0935 - learning_rate: 0.0010\nEpoch 4/8\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519ms/step - accuracy: 0.3427 - loss: 1.0977\nEpoch 4: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 540ms/step - accuracy: 0.3427 - loss: 1.0977 - val_accuracy: 0.3717 - val_loss: 1.0909 - learning_rate: 0.0010\nEpoch 5/8\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 537ms/step - accuracy: 0.3757 - loss: 1.0944 - val_accuracy: 0.3920 - val_loss: 1.0883 - learning_rate: 3.0000e-04\nEpoch 6/8\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 541ms/step - accuracy: 0.3756 - loss: 1.0934 - val_accuracy: 0.5105 - val_loss: 1.0856 - learning_rate: 3.0000e-04\nEpoch 7/8\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 539ms/step - accuracy: 0.3840 - loss: 1.0922 - val_accuracy: 0.5077 - val_loss: 1.0841 - learning_rate: 3.0000e-04\nEpoch 8/8\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 540ms/step - accuracy: 0.3810 - loss: 1.0931 - val_accuracy: 0.3738 - val_loss: 1.0827 - learning_rate: 3.0000e-04\n\nâœ… Phase 2: Fine-tuning full model for Potato diseases...\nEpoch 1/20\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 929ms/step - accuracy: 0.4408 - loss: 1.1708 - val_accuracy: 0.7889 - val_loss: 0.7603 - learning_rate: 1.0000e-05\nEpoch 2/20\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 588ms/step - accuracy: 0.7272 - loss: 0.7578 - val_accuracy: 0.9628 - val_loss: 0.5142 - learning_rate: 1.0000e-05\nEpoch 3/20\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 586ms/step - accuracy: 0.8944 - loss: 0.5473 - val_accuracy: 0.9867 - val_loss: 0.3717 - learning_rate: 1.0000e-05\nEpoch 4/20\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 585ms/step - accuracy: 0.9490 - loss: 0.4391 - val_accuracy: 0.9937 - val_loss: 0.3489 - learning_rate: 1.0000e-05\nEpoch 5/20\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 590ms/step - accuracy: 0.9585 - loss: 0.4112 - val_accuracy: 0.9958 - val_loss: 0.3395 - learning_rate: 1.0000e-05\nEpoch 6/20\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 578ms/step - accuracy: 0.9644 - loss: 0.3981 - val_accuracy: 0.9958 - val_loss: 0.3333 - learning_rate: 1.0000e-05\nEpoch 7/20\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 585ms/step - accuracy: 0.9706 - loss: 0.3886 - val_accuracy: 0.9972 - val_loss: 0.3284 - learning_rate: 1.0000e-05\nEpoch 8/20\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 576ms/step - accuracy: 0.9749 - loss: 0.3761 - val_accuracy: 1.0000 - val_loss: 0.3225 - learning_rate: 1.0000e-05\nEpoch 9/20\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 589ms/step - accuracy: 0.9789 - loss: 0.3692 - val_accuracy: 0.9993 - val_loss: 0.3186 - learning_rate: 1.0000e-05\nEpoch 10/20\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 576ms/step - accuracy: 0.9823 - loss: 0.3615 - val_accuracy: 1.0000 - val_loss: 0.3162 - learning_rate: 1.0000e-05\nEpoch 11/20\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 571ms/step - accuracy: 0.9864 - loss: 0.3536 - val_accuracy: 0.9993 - val_loss: 0.3134 - learning_rate: 1.0000e-05\nEpoch 12/20\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 573ms/step - accuracy: 0.9909 - loss: 0.3470 - val_accuracy: 1.0000 - val_loss: 0.3109 - learning_rate: 1.0000e-05\nEpoch 13/20\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 572ms/step - accuracy: 0.9849 - loss: 0.3483 - val_accuracy: 1.0000 - val_loss: 0.3080 - learning_rate: 1.0000e-05\nEpoch 14/20\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 573ms/step - accuracy: 0.9893 - loss: 0.3421 - val_accuracy: 0.9993 - val_loss: 0.3070 - learning_rate: 1.0000e-05\nEpoch 15/20\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 575ms/step - accuracy: 0.9884 - loss: 0.3415 - val_accuracy: 1.0000 - val_loss: 0.3053 - learning_rate: 1.0000e-05\nEpoch 16/20\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 580ms/step - accuracy: 0.9910 - loss: 0.3334 - val_accuracy: 1.0000 - val_loss: 0.3042 - learning_rate: 1.0000e-05\nEpoch 17/20\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 574ms/step - accuracy: 0.9912 - loss: 0.3362 - val_accuracy: 1.0000 - val_loss: 0.3041 - learning_rate: 1.0000e-05\nEpoch 18/20\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 571ms/step - accuracy: 0.9888 - loss: 0.3358 - val_accuracy: 1.0000 - val_loss: 0.3026 - learning_rate: 1.0000e-05\nEpoch 19/20\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 573ms/step - accuracy: 0.9923 - loss: 0.3313 - val_accuracy: 0.9993 - val_loss: 0.3017 - learning_rate: 1.0000e-05\nEpoch 20/20\n\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 583ms/step - accuracy: 0.9907 - loss: 0.3336 - val_accuracy: 0.9993 - val_loss: 0.3027 - learning_rate: 1.0000e-05\n\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.9998 - loss: 0.3008\n\nâœ… Final Validation Accuracy for Potato: 0.9993\nğŸ”» Final Validation Loss for Potato: 0.3017\n\nClass Indices: {'Potato___Early_blight': 0, 'Potato___Late_blight': 1, 'Potato___healthy': 2}\n\n==================================================\nğŸš€ Starting training for Rice crop\n==================================================\n\nPreprocessing training data...\n","output_type":"stream"},{"name":"stderr","text":"Processing Rice_Brownspot: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2219/2219 [00:29<00:00, 75.39it/s]\nProcessing Rice blast: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1044/1044 [00:16<00:00, 64.58it/s]\nProcessing Rice Tungro: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1308/1308 [00:17<00:00, 74.61it/s]\nProcessing Rice hispa: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 957/957 [00:14<00:00, 64.77it/s]\nProcessing rice_smut: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:03<00:00, 73.63it/s]\nProcessing rice_sheath_blight: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 151/151 [00:02<00:00, 72.11it/s]\nProcessing rice_bacterial_leaf_streak: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 378/378 [00:05<00:00, 65.92it/s]\nProcessing rice_bacterial_leaf_blight: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 270/270 [00:04<00:00, 64.47it/s]\nProcessing Rice Healthy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1059/1059 [00:16<00:00, 65.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Preprocessing validation data...\n","output_type":"stream"},{"name":"stderr","text":"Processing Rice_Brownspot: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 202/202 [00:03<00:00, 67.06it/s]\nProcessing Rice blast: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:05<00:00, 69.07it/s]\nProcessing Rice Tungro: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 97.61it/s]\nProcessing Rice hispa: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 318/318 [00:04<00:00, 65.80it/s]\nProcessing rice_smut: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:00<00:00, 74.51it/s]\nProcessing rice_sheath_blight: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:00<00:00, 79.64it/s]\nProcessing rice_bacterial_leaf_streak: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:01<00:00, 68.23it/s]\nProcessing rice_bacterial_leaf_blight: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:01<00:00, 64.99it/s]\nProcessing Rice Healthy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 352/352 [00:05<00:00, 63.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Number of Rice disease classes: 9\nFound 7610 images belonging to 9 classes.\nFound 1611 images belonging to 9 classes.\n\nâœ… Phase 1: Training classifier head for Rice diseases...\nEpoch 1/8\n\u001b[1m238/238\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 675ms/step - accuracy: 0.2743 - loss: 2.0170 - val_accuracy: 0.1949 - val_loss: 2.1435 - learning_rate: 0.0010\nEpoch 2/8\n\u001b[1m238/238\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 541ms/step - accuracy: 0.3107 - loss: 1.9059 - val_accuracy: 0.1906 - val_loss: 2.1444 - learning_rate: 0.0010\nEpoch 3/8\n\u001b[1m238/238\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 542ms/step - accuracy: 0.3127 - loss: 1.9016 - val_accuracy: 0.1974 - val_loss: 2.0929 - learning_rate: 0.0010\nEpoch 4/8\n\u001b[1m238/238\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 543ms/step - accuracy: 0.3203 - loss: 1.8857 - val_accuracy: 0.2483 - val_loss: 2.0667 - learning_rate: 0.0010\nEpoch 5/8\n\u001b[1m238/238\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 535ms/step - accuracy: 0.3192 - loss: 1.8750 - val_accuracy: 0.1943 - val_loss: 2.1004 - learning_rate: 0.0010\nEpoch 6/8\n\u001b[1m238/238\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523ms/step - accuracy: 0.3182 - loss: 1.8762\nEpoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n\u001b[1m238/238\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 543ms/step - accuracy: 0.3182 - loss: 1.8761 - val_accuracy: 0.2495 - val_loss: 2.0879 - learning_rate: 0.0010\nEpoch 7/8\n\u001b[1m238/238\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 534ms/step - accuracy: 0.3275 - loss: 1.8501 - val_accuracy: 0.2185 - val_loss: 2.0477 - learning_rate: 3.0000e-04\nEpoch 8/8\n\u001b[1m238/238\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 543ms/step - accuracy: 0.3289 - loss: 1.8441 - val_accuracy: 0.2067 - val_loss: 2.0538 - learning_rate: 3.0000e-04\n\nâœ… Phase 2: Fine-tuning full model for Rice diseases...\nEpoch 1/20\n\u001b[1m137/238\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m56s\u001b[0m 562ms/step - accuracy: 0.2924 - loss: 2.2896","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1751592669.485199     115 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1751592669.629211     115 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1751592670.141236     115 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1751592670.288916     115 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}